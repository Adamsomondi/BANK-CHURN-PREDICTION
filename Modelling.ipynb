{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0rJwMkDYDHJa","executionInfo":{"status":"ok","timestamp":1744297871511,"user_tz":-180,"elapsed":6181,"user":{"displayName":"Adams nogo","userId":"04938037951963737511"}},"outputId":"3f0a573b-a70c-4ef7-8c80-99348ce94a8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","git is already the newest version (1:2.34.1-1ubuntu1.12).\n","0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n","/content\n","fatal: destination path 'BANK-CHURN-PREDICTION' already exists and is not an empty directory.\n","/content/BANK-CHURN-PREDICTION\n","total 520\n","drwxr-xr-x 3 root root   4096 Apr 10 15:04 .\n","drwxr-xr-x 1 root root   4096 Apr 10 15:04 ..\n","-rw-r--r-- 1 root root 508305 Apr 10 15:04 DataAnalysis.ipynb\n","drwxr-xr-x 8 root root   4096 Apr 10 15:04 .git\n","-rw-r--r-- 1 root root     22 Apr 10 15:04 .gitignore\n","-rw-r--r-- 1 root root    523 Apr 10 15:04 README.md\n"]}],"source":["\n","!apt install git\n","\n","# Change to your working directory.\n","%cd /content\n","\n","# Clone the shared GitHub repository.\n","!git clone https://github.com/Adamsomondi/BANK-CHURN-PREDICTION.git\n","\n","# Move into the repo.\n","%cd BANK-CHURN-PREDICTION\n","\n","# Checks the contents of the repository.\n","!ls -la"]},{"cell_type":"markdown","source":["**DATA MODELLING**"],"metadata":{"id":"2xsCa_lhD1Fc"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from sklearn.preprocessing import StandardScaler\n","\n","# Load the dataset\n","cleanedfile_id = \"1-nx-ESuJAJxHoDfZaZgk56AuwVsY7SDD\"\n","cleanedfile_url = f\"https://drive.google.com/uc?id={cleanedfile_id}\"\n","df = pd.read_csv(cleanedfile_url)\n","\n","# Make sure the target column is binary\n","if df['Exited'].dtype not in [int, 'category']:\n","    df['Exited'] = (df['Exited'] > 0).astype(int)\n","\n","# Separate features and target\n","X = df.drop(columns=['Exited'])\n","y = df['Exited']\n","\n","# Scale features (important for Logistic Regression!)\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Split data\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n","\n","# Set up hyperparameter grid\n","param_grid = {\n","    'C': [0.01, 0.1, 1, 10, 100],         # Regularization strength (smaller = stronger regularization)\n","    'solver': ['liblinear', 'lbfgs'],    # Solvers the method the robot uses to learn\n","    'penalty': ['l2']                    # is like a rule that helps the robot avoid overfitting\n","}\n","# Initialize the model\n","log_reg = LogisticRegression(random_state=45, max_iter=1000)\n","\n","# Perform grid search\n","grid = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy')\n","grid.fit(X_train, y_train)\n","\n","# Best model\n","best_model = grid.best_estimator_\n","print(\"Best Parameters:\", grid.best_params_)\n","\n","# Make predictions with the best model\n","y_pred = best_model.predict(X_test)\n","\n","# Evaluate the model\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n","print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"],"metadata":{"id":"h5NiK850u5t5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744297879175,"user_tz":-180,"elapsed":4826,"user":{"displayName":"Adams nogo","userId":"04938037951963737511"}},"outputId":"63766bd0-6938-4159-c3be-108db1d3da9a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Parameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n","Accuracy: 0.999\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1607\n","           1       1.00      1.00      1.00       393\n","\n","    accuracy                           1.00      2000\n","   macro avg       1.00      1.00      1.00      2000\n","weighted avg       1.00      1.00      1.00      2000\n","\n","\n","Confusion Matrix:\n"," [[1606    1]\n"," [   1  392]]\n"]}]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","# Set up hyperparameter grid for Random Forest\n","param_grid_rf = {\n","    'n_estimators': [50, 100, 150],   # Number of trees in the forest\n","    'max_depth': [None, 10, 20, 30],   # Maximum depth of each tree\n","    'min_samples_split': [2, 5, 10]    # Minimum number of samples to split an internal node\n","}\n","\n","# Initialize Random Forest Classifier\n","rf_classifier = RandomForestClassifier(random_state=45)\n","\n","# Perform GridSearchCV for hyperparameter tuning\n","grid_rf = GridSearchCV(rf_classifier, param_grid_rf, cv=5, scoring='accuracy')\n","grid_rf.fit(X_train, y_train)\n","\n","# Best model after tuning\n","best_rf_model = grid_rf.best_estimator_\n","print(\"Best Random Forest Parameters:\", grid_rf.best_params_)\n","\n","# Make predictions with the best model\n","y_pred_rf = best_rf_model.predict(X_test)\n","\n","# Evaluate the Random Forest model\n","print(\"Random Forest - Accuracy:\", accuracy_score(y_test, y_pred_rf))\n","print(\"\\nClassification Report (Random Forest):\\n\", classification_report(y_test, y_pred_rf))\n","print(\"\\nConfusion Matrix (Random Forest):\\n\", confusion_matrix(y_test, y_pred_rf))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58_eI79kJCPb","executionInfo":{"status":"ok","timestamp":1744298175860,"user_tz":-180,"elapsed":106818,"user":{"displayName":"Adams nogo","userId":"04938037951963737511"}},"outputId":"923c5d2b-86d1-46d7-9840-f473af87506d"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Random Forest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n","Random Forest - Accuracy: 0.999\n","\n","Classification Report (Random Forest):\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1607\n","           1       1.00      1.00      1.00       393\n","\n","    accuracy                           1.00      2000\n","   macro avg       1.00      1.00      1.00      2000\n","weighted avg       1.00      1.00      1.00      2000\n","\n","\n","Confusion Matrix (Random Forest):\n"," [[1606    1]\n"," [   1  392]]\n"]}]},{"cell_type":"code","source":["# Comparing accuracy scores\n","logreg_accuracy = accuracy_score(y_test, y_pred)\n","rf_accuracy = accuracy_score(y_test, y_pred)\n","\n","print(\"Logistic Regression Accuracy:\", logreg_accuracy)\n","print(\"Random Forest Accuracy:\", rf_accuracy)\n","\n","# In this case, we can use the model with the higher accuracy (or other metrics like F1-score) as the best model\n","if logreg_accuracy > rf_accuracy:\n","    print(\"Logistic Regression is the best model based on accuracy.\")\n","else:\n","    print(\"Random Forest is the best model based on accuracy.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EYsDMr_WJqgA","executionInfo":{"status":"ok","timestamp":1744298187967,"user_tz":-180,"elapsed":20,"user":{"displayName":"Adams nogo","userId":"04938037951963737511"}},"outputId":"d2fb4b82-b946-4cc5-fc22-917406cc9024"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Logistic Regression Accuracy: 0.999\n","Random Forest Accuracy: 0.999\n","Random Forest is the best model based on accuracy.\n"]}]},{"cell_type":"code","source":["# Comparison rationale\n","print(\"\\nRationale for Model Selection:\")\n","\n","# Compare accuracies\n","print(f\"\\nLogistic Regression Accuracy: {logreg_accuracy}\")\n","print(f\"Random Forest Accuracy: {rf_accuracy}\")\n","\n","# Compare based on F1-score (harmonic mean of precision and recall)\n","logreg_f1_score = classification_report(y_test, y_pred, output_dict=True)['weighted avg']['f1-score']\n","rf_f1_score = classification_report(y_test, y_pred_rf, output_dict=True)['weighted avg']['f1-score']\n","\n","print(f\"Logistic Regression F1-Score: {logreg_f1_score}\")\n","print(f\"Random Forest F1-Score: {rf_f1_score}\")\n","\n","# Rationalize the model choice\n","if rf_accuracy > logreg_accuracy and rf_f1_score > logreg_f1_score:\n","    print(\"\\nRandom Forest is the better model based on accuracy and F1-score.\")\n","elif logreg_accuracy > rf_accuracy and logreg_f1_score > rf_f1_score:\n","    print(\"\\nLogistic Regression is the better model based on accuracy and F1-score.\")\n","else:\n","    print(\"\\nBoth models perform similarly. Further analysis, such as cross-validation, could be considered.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m7bejXdxJ2_7","executionInfo":{"status":"ok","timestamp":1744298235200,"user_tz":-180,"elapsed":98,"user":{"displayName":"Adams nogo","userId":"04938037951963737511"}},"outputId":"71bf4057-6a04-4312-a0ef-cbd8fe23bf5c"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Rationale for Model Selection:\n","\n","Logistic Regression Accuracy: 0.999\n","Random Forest Accuracy: 0.999\n","Logistic Regression F1-Score: 0.999\n","Random Forest F1-Score: 0.999\n","\n","Both models perform similarly. Further analysis, such as cross-validation, could be considered.\n"]}]},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.preprocessing import StandardScaler\n","import pandas as pd\n","import numpy as np\n","\n","# Load the dataset\n","cleanedfile_id = \"1-nx-ESuJAJxHoDfZaZgk56AuwVsY7SDD\"\n","cleanedfile_url = f\"https://drive.google.com/uc?id={cleanedfile_id}\"\n","df = pd.read_csv(cleanedfile_url)\n","\n","# Preprocess the target column to be binary (0 or 1)\n","if df['Exited'].dtype not in [int, 'category']:\n","    df['Exited'] = (df['Exited'] > 0).astype(int)\n","\n","# Separate features and target\n","X = df.drop(columns=['Exited'])\n","y = df['Exited']\n","\n","# Scale features (important for Logistic Regression)\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Initialize models\n","log_reg = LogisticRegression(random_state=42, max_iter=1000)\n","rf_classifier = RandomForestClassifier(random_state=45)\n","\n","# Perform cross-validation for Logistic Regression\n","log_reg_cv_scores = cross_val_score(log_reg, X_scaled, y, cv=5, scoring='accuracy')\n","\n","# Perform cross-validation for Random Forest\n","rf_cv_scores = cross_val_score(rf_classifier, X_scaled, y, cv=5, scoring='accuracy')\n","\n","# Print cross-validation results for Logistic Regression\n","print(\"Logistic Regression Cross-Validation Results:\")\n","print(f\"Cross-validation scores (Accuracy) for each fold: {log_reg_cv_scores}\")\n","print(f\"Mean accuracy: {log_reg_cv_scores.mean()}\")\n","print(f\"Standard deviation: {log_reg_cv_scores.std()}\")\n","\n","# Print cross-validation results for Random Forest\n","print(\"\\nRandom Forest Cross-Validation Results:\")\n","print(f\"Cross-validation scores (Accuracy) for each fold: {rf_cv_scores}\")\n","print(f\"Mean accuracy: {rf_cv_scores.mean()}\")\n","print(f\"Standard deviation: {rf_cv_scores.std()}\")\n","\n","# Evaluate models using the mean accuracy score from cross-validation\n","print(\"\\nModel Evaluation Based on Cross-Validation Results:\")\n","if log_reg_cv_scores.mean() > rf_cv_scores.mean():\n","    print(\"\\nLogistic Regression is the better model based on mean cross-validation accuracy.\")\n","else:\n","    print(\"\\nRandom Forest is the better model based on mean cross-validation accuracy.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xmYQXllCKQCY","executionInfo":{"status":"ok","timestamp":1744298284217,"user_tz":-180,"elapsed":6651,"user":{"displayName":"Adams nogo","userId":"04938037951963737511"}},"outputId":"58b79f18-2cc1-42c7-817f-d81d7fe8e9a8"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Logistic Regression Cross-Validation Results:\n","Cross-validation scores (Accuracy) for each fold: [0.995 1.    1.    1.    0.998]\n","Mean accuracy: 0.9986\n","Standard deviation: 0.0019595917942265445\n","\n","Random Forest Cross-Validation Results:\n","Cross-validation scores (Accuracy) for each fold: [0.995 1.    1.    1.    0.998]\n","Mean accuracy: 0.9986\n","Standard deviation: 0.0019595917942265445\n","\n","Model Evaluation Based on Cross-Validation Results:\n","\n","Random Forest is the better model based on mean cross-validation accuracy.\n"]}]},{"cell_type":"code","source":["#Mount the drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","!ls -la \"/content/drive/My Drive/Colab Notebooks\"\n","!find \"/content/drive/My Drive\" -name \"Modelling.ipynb\"\n","!cp \"/content/drive/My Drive/Colab Notebooks/Modelling.ipynb\" /content/BANK-CHURN-PREDICTION/\n","\n","!ls -la \"/content/BANK-CHURN-PREDICTION/\""],"metadata":{"id":"NmuunpozR9wF"},"execution_count":null,"outputs":[]}]}